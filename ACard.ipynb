{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 信贷申请评分卡_A卡案例\n",
    "\n",
    "主要项目流程：数据获取、数据清洗(特征初筛)、特征工程、模型建立与评价等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import catboost as cat\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % config ZMQInteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.数据获取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据基本描述：信贷申请数据--42535个样本，144个特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('LoanStats_2018Q3.xlsx')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征列表\n",
    "feature_list = list(data)\n",
    "print(feature_list)\n",
    "df = data.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.数据清洗（特征初筛）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 申请评分卡使用的数据不能是借款人借款后的信息，需删除18个特征\n",
    "del_feature_list = ['sub_grade','grade','initial_list_status','out_prncp','out_prncp_inv','total_pymnt','total_pymnt_inv',\n",
    "                    'total_rec_prncp','total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee','last_pymnt_d',\n",
    "                    'last_pymnt_amnt','last_credit_pull_d','collections_12_mths_ex_med','policy_code','disbursement_method']\n",
    "print(df.shape)\n",
    "df_01 = df.copy().drop(columns=del_feature_list, axis=1)\n",
    "print(df_01.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 删除客户隐私的字段:['emp_title','title']\n",
    "customer_info = ['emp_title','title']\n",
    "df_02 = df_01.drop(columns=customer_info, axis=1)\n",
    "df_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 去重，删除空行\n",
    "df_03 = df_02.drop_duplicates('id').dropna(axis=0, how='all')\n",
    "df_03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 删除缺失率大于0.95的字段\n",
    "# is_null = [df_03[i_feature].isnull().sum() for i_feature in list(df_03)]\n",
    "cols_null = []\n",
    "for col_null in df_03.columns:\n",
    "    if df_03[col_null].isnull().sum() > (df_03.shape[0])*0.95:\n",
    "        cols_null.append(col_null)\n",
    "print(len(cols_null))\n",
    "df_04 = df_03.drop(cols_null, axis=1)\n",
    "df_04.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 例：唯一值\n",
    "# 2.5 判断每个特征值的分布，若存在某一个值占比超过95%，则删除(分箱前提)\n",
    "col_handle = []\n",
    "for col_ in df_04.columns:\n",
    "    if df_04[col_].value_counts().max() > df_04.shape[0]*0.95:\n",
    "        col_handle.append(col_)\n",
    "print(col_handle)\n",
    "df_05 = df_04.drop(col_handle, axis=1)\n",
    "df_05.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.6 删除id号\n",
    "df_06 = df_05.drop('id', axis=1)\n",
    "df_06.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7 查看借款期限，并选出借款36期的样本\n",
    "print(df_06['term'].value_counts())\n",
    "df_06['term'] = df_06['term'].replace(' 36 months', 36).replace(' 60 months', 60)\n",
    "df_final = df_06[df_06['term']==36]\n",
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.8 数据类型查看与转换\n",
    "def obj_feature(df_final):\n",
    "    obj_feature = []\n",
    "    for obj_f in df_final.columns:\n",
    "        if df_final[obj_f].dtypes == 'object':\n",
    "            obj_feature.append(obj_f)\n",
    "    print(obj_feature)\n",
    "    return obj_feature\n",
    "\n",
    "obj_feature = obj_feature(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征值查看\n",
    "# 1) emp_length--工作年限\n",
    "df_finals = df_final.copy()\n",
    "# print(df_finals['emp_length'].value_counts())\n",
    "print(df_finals['emp_length'].unique())\n",
    "\n",
    "def emp_length_new(x):\n",
    "    if x=='< 1 year':\n",
    "        return 0\n",
    "    elif x=='1 year':\n",
    "        return 1\n",
    "    elif x=='10+ years':\n",
    "        return 11\n",
    "    elif str(x)=='nan':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return x.replace(' years', '')\n",
    "    \n",
    "df_finals['emp_length'] =df_finals['emp_length'].map(lambda x: emp_length_new(x))\n",
    "df_finals['emp_length'].unique()\n",
    "df_finals['emp_length'] = df_finals['emp_length'].apply(pd.to_numeric, errors='coerce')\n",
    "# print('===================================')\n",
    "\n",
    "# 2) home_ownership--房产权:类别型特征\n",
    "# print(df_finals['home_ownership'].value_counts())\n",
    "# print('===================================')\n",
    "\n",
    "# 3) verification_status--验证状态:类别型特征\n",
    "# print(df_finals['verification_status'].value_counts())\n",
    "# print('===================================')\n",
    "\n",
    "# 4) loan_status--贷款状态:y\n",
    "# df_finals['loan_status'].value_counts()\n",
    "df_finals['loan_status'] = df_finals['loan_status'].copy().map(lambda x: 1 if 'Charged Off' in x else 0)\n",
    "# print(df_finals['loan_status'].value_counts())\n",
    "# print('===================================')\n",
    "\n",
    "# 5) desc--自然语言模块，暂不考虑\n",
    "df_finals = df_finals.drop('desc', axis=1)\n",
    "# print('===================================')\n",
    "\n",
    "# 6) purpose--用途：类别型特征\n",
    "# print(df_finals['purpose'].value_counts())\n",
    "# print('===================================')\n",
    "\n",
    "# 7) zip_code--邮政编码\n",
    "df_finals = df_finals.drop('zip_code', axis=1)\n",
    "# print('===================================')\n",
    "\n",
    "# 8) addr_state--地址状态：类别型特征\n",
    "# print(df_finals['addr_state'].value_counts())\n",
    "# print('===================================')\n",
    "\n",
    "# 9) delinq_2yrs：过去两年逾期次数\n",
    "# print(df_finals['delinq_2yrs'].value_counts())\n",
    "set(df_finals['delinq_2yrs'])\n",
    "df_finals['delinq_2yrs'] = df_finals['delinq_2yrs'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# 10) total_acc\n",
    "set(df_finals['total_acc'])\n",
    "df_finals['total_acc'] = df_finals['total_acc'].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.9 特征衍生：loan_amnt贷款额度，annual_inc年收入（贷款收入比）\n",
    "# df_finals[['loan_amnt','annual_inc', 'issue_d', 'earliest_cr_line', 'next_pymnt_d']]\n",
    "df_finals['pnt_loan_annual'] = df_finals.loan_amnt/df_finals.annual_inc\n",
    "print(df_finals.shape)\n",
    "df_finals.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征列表分类\n",
    "# 离散(类别型)特征:home_ownership, verification_status, purpose, addr_state\n",
    "char_feature = ['emp_length', 'home_ownership', 'verification_status', 'purpose', 'addr_state']\n",
    "\n",
    "# 日期型特征：issue_d，earliest_cr_line，next_pymnt_d\n",
    "time_feature = ['issue_d', 'earliest_cr_line', 'next_pymnt_d']\n",
    "df_finals[time_feature] = df_finals[time_feature].apply(pd.to_datetime)\n",
    "\n",
    "# 标签\n",
    "df_label=['loan_status']\n",
    "\n",
    "# 连续型特征\n",
    "num_feature = df_finals.copy().columns.drop(time_feature).drop(char_feature).drop(df_label)\n",
    "for i_f in num_feature:\n",
    "    df_finals[i_f] = df_finals[i_f].apply(pd.to_numeric, errors='coerce')\n",
    "print(len(num_feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *数据探索\n",
    "# 类别型(离散)特征: 每个特征值分布概率值\n",
    "def data_distributed(df_finals, char_feature):\n",
    "    rate_feature_all = []\n",
    "    for col in char_feature:\n",
    "        result = df_finals[col].value_counts()\n",
    "        #print('char_feature_name:', col)\n",
    "        rate_feature = []\n",
    "        for v_i in range(len(result)):\n",
    "            rate = result[v_i]/result.sum()\n",
    "            rate_feature.append(rate)\n",
    "        rate_feature = pd.Series(rate_feature).to_frame().reset_index().rename(columns={'index':'id', 0: 'rate'})\n",
    "        result = pd.Series(result).to_frame().reset_index().reset_index().rename(columns={'level_0':'id', 'index':'f_name',\n",
    "                                                                                          'home_ownership':'value_count'})\n",
    "        rate_feature = pd.merge(result, rate_feature, on=['id']).drop('id', axis=1)\n",
    "        rate_feature_all.append(rate_feature)\n",
    "    return rate_feature_all\n",
    "\n",
    "df_finals['emp_length'] = df_finals['emp_length'].astype('str')\n",
    "# df_finals['emp_length'].dtypes\n",
    "rate_feature_all = data_distributed(df_finals, char_feature)\n",
    "# rate_feature_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 2.10 缺失值查看与处理\n",
    "# 离散特征\n",
    "print(df_finals[char_feature].isnull().sum())\n",
    "print('==============next=============')\n",
    "\n",
    "# 连续型特征\n",
    "print(df_finals[num_feature].isnull().sum())\n",
    "# 缺失值处理：-999填充\n",
    "df_s = df_finals.fillna(-999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重命名与定义y标签：贷款状态(好样本0，坏样本1)\n",
    "df_s=df_s.rename(columns={'loan_status':'y'})\n",
    "df_s['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.特征工程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据iv值、相关性、多重共线性等筛选特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散：计算每个特征的iv值\n",
    "def cal_charf_iv(char_df, label):\n",
    "#     print(char_df.shape, '\\n====计算离散特征的iv值====')\n",
    "    all_feature_iv = []\n",
    "    char_feature_name = []\n",
    "    for char_f in list(char_df):\n",
    "        if char_f not in label:\n",
    "            char_feature_name.append(char_f)\n",
    "            #print('feature:', char_f)\n",
    "            df = pd.concat([char_df[char_f], char_df[label]], axis=1)\n",
    "            #print(df.shape)\n",
    "            # 好样本统计\n",
    "            good_df = df[df[label]==0]\n",
    "            good_count = good_df[char_f].value_counts().to_frame().reset_index().rename(columns={'index':'char_value',char_f:'good_count'})\n",
    "            # 坏样本统计\n",
    "            bad_df = df[df[label]==1]\n",
    "            bad_count = bad_df[char_f].value_counts().to_frame().reset_index().rename(columns={'index':'char_value',char_f:'bad_count'})\n",
    "            # 整合\n",
    "            result_df = pd.merge(good_count, bad_count, on=['char_value'])\n",
    "            result_df['good_rate'] = result_df.good_count/result_df.good_count.sum() # 好客户的占比\n",
    "            result_df['bad_rate'] = result_df.bad_count/result_df.bad_count.sum() # 坏客户的占比\n",
    "            result_df['cum_good_rate'] = result_df.good_rate.cumsum()\n",
    "            result_df['cum_bad_rate'] = result_df.bad_rate.cumsum()\n",
    "            # 计算ks\n",
    "            result_df['ks'] = round(abs(result_df.cum_good_rate - result_df.cum_bad_rate), 4)\n",
    "            # 计算woe(优势比):ln(好客户的占比/坏客户的占比)*100%\n",
    "            result_df['woe'] = np.log(result_df.good_rate/result_df.bad_rate)\n",
    "            result_df['iv'] = (result_df.good_rate-result_df.bad_rate)*(result_df.woe)\n",
    "            feature_iv = result_df.iv.sum()\n",
    "            #print('feature_iv:',feature_iv)\n",
    "            #print(str(char_f + ':'), feature_iv)\n",
    "            all_feature_iv.append(feature_iv)\n",
    "    feature_iv = pd.Series(all_feature_iv).to_frame().rename(columns={0:'feature_iv'})\n",
    "    feature_name = pd.Series(char_feature_name).to_frame().rename(columns={0:'feature_name'})\n",
    "    feature_name_iv = pd.concat([feature_name, feature_iv], axis=1)\n",
    "    return feature_name_iv\n",
    "\n",
    "# 连续型：计算每个特征的iv值\n",
    "def cal_numf_iv(num_df, label):\n",
    "#     print(num_df.shape, '\\n=========计算连续特征的iv值=========')\n",
    "    all_feature_iv = []\n",
    "    num_feature_name = []\n",
    "#     print(list(num_df))\n",
    "    for num_f in list(num_df):\n",
    "        if num_f not in label:\n",
    "            #print(num_f)\n",
    "            num_feature_name.append(num_f)\n",
    "            # 分箱操作--等频：10等份\n",
    "            df_bin = pd.qcut(df_s[num_f], 10, duplicates='drop')\n",
    "            df_bin_label = pd.concat([df_bin, df_s[label]], axis=1)\n",
    "            # 好样本统计\n",
    "            good_bin_df = df_bin_label[df_bin_label[label]==0].rename(columns={num_f:'bin'})\n",
    "            good_count = good_bin_df['bin'].value_counts().to_frame().reset_index().rename(columns={'index':'bin', \n",
    "                                                                                                    'bin':'good_count'}).sort_values(by='bin')\n",
    "            # 坏样本统计\n",
    "            bad_bin_df = df_bin_label[df_bin_label[label]==1].rename(columns={num_f:'bin'})\n",
    "            bad_count = bad_bin_df['bin'].value_counts().to_frame().reset_index().rename(columns={'index':'bin', \n",
    "                                                                                                  'bin':'bad_count'}).sort_values(by='bin')\n",
    "            # 合并统计结果\n",
    "            result_df = pd.merge(good_count, bad_count, on=['bin'])\n",
    "            result_df['good_rate'] = result_df.good_count/result_df.good_count.sum()\n",
    "            result_df['bad_rate'] = result_df.bad_count/result_df.bad_count.sum()\n",
    "            result_df['cum_good_rate'] = result_df.good_rate.cumsum()\n",
    "            result_df['cum_bad_rate'] = result_df.bad_rate.cumsum()\n",
    "            # 计算ks\n",
    "            result_df['ks'] = round(abs(result_df.cum_good_rate - result_df.cum_bad_rate), 6)\n",
    "            # 计算iv值\n",
    "            result_df['woe'] = np.log(result_df.good_rate/result_df.bad_rate)\n",
    "            result_df['iv'] = (result_df.good_rate-result_df.bad_rate)*(result_df.woe)\n",
    "            feature_iv = result_df.iv.sum()\n",
    "            all_feature_iv.append(feature_iv)\n",
    "    feature_iv = pd.Series(all_feature_iv).to_frame().rename(columns={0:'feature_iv'})\n",
    "    feature_name = pd.Series(num_feature_name).to_frame().rename(columns={0:'feature_name'})\n",
    "    num_feature_name_iv = pd.concat([feature_name, feature_iv], axis=1)\n",
    "    return num_feature_name_iv\n",
    "\n",
    "def get_result_iv(feature_name_iv, low_th, high_th):\n",
    "    # 特征iv值：评价指标\n",
    "    #    a.iv<0.02, 预测效果：无明显；\n",
    "    #    b.0.02=<iv<0.1, 预测效果：弱； \n",
    "    #    c.0.1=<iv<0.3, 预测效果：中等；\n",
    "    #    d.0.3=<iv<0.5, 预测效果：强；\n",
    "    #    e.0.5=<iv, 预测效果：需考虑；\n",
    "    len_f = feature_name_iv.shape[0]\n",
    "    threshold_high = feature_name_iv[feature_name_iv.feature_iv<high_th].shape[0]\n",
    "    threshold_low = feature_name_iv[feature_name_iv.feature_iv>=low_th].shape[0]\n",
    "    if threshold_high==len_f and threshold_low==len_f:\n",
    "        print('all feature...')\n",
    "    else:\n",
    "        print('some feature...')\n",
    "    # 选取iv值在固定范围的特征,若整体iv值不高，可稍微适当调整\n",
    "    feature_sel = feature_name_iv[feature_name_iv.feature_iv>=low_th]\n",
    "    feature_sels = feature_sel[feature_sel.feature_iv<high_th]\n",
    "    return feature_sels\n",
    "\n",
    "# 根据相关性、iv值，综合考虑特征\n",
    "def del_feature_sub(sn_df, numf_vi, th_c):\n",
    "    del_feature_sub = []\n",
    "    for i in range(sn_df.shape[1]):\n",
    "        for j in range(sn_df.shape[1]):\n",
    "            if i==j:\n",
    "                continue\n",
    "            else:\n",
    "                if sn_df.iloc[i][j]>=th_c:\n",
    "                    numf_vi_i = numf_vi.iloc[i, 1]\n",
    "                    numf_vi_j = numf_vi.iloc[j, 1]\n",
    "                    if numf_vi_i>=numf_vi_j:\n",
    "                        del_feature_sub.append(numf_vi.iloc[j, 0])\n",
    "    del_feature_subs = list(set(del_feature_sub)) # 可删除特征字段\n",
    "    return del_feature_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 柱状图\n",
    "def plot_histogram(df):\n",
    "    all_feature_iv_list = list(df.feature_name)\n",
    "    all_feature_iv_df = df.feature_iv\n",
    "    plt.bar(range(len(all_feature_iv_list)), all_feature_iv_df, color='rgby')\n",
    "    plt.show()\n",
    "    \n",
    "# 热力图\n",
    "def plot_seaborn(df):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sn.heatmap(df, annot=True)\n",
    "    plt.title(\"The feature's heatmap\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 根据iv值筛选特征\n",
    "# 1)离散(类别型)特征\n",
    "char_df = pd.concat([df_s[char_feature], df_s['y']], axis=1)\n",
    "feature_name_iv = cal_charf_iv(char_df, label='y')\n",
    "feature_name_iv\n",
    "\n",
    "# 2) 连续性特征\n",
    "num_features = num_feature.copy().drop('term')\n",
    "num_df = df_s[num_features]\n",
    "num_df.shape\n",
    "num_feature_name_iv = cal_numf_iv(num_df, label='y')\n",
    "num_feature_name_iv\n",
    "\n",
    "# 3)合并离散和连续的特征iv值\n",
    "all_feature_iv = pd.concat([feature_name_iv, num_feature_name_iv],axis=0).reset_index().drop('index', axis=1)\n",
    "all_feature_iv\n",
    " \n",
    "# 4) 特征筛选_取iv值范围：[0.01, 0.5)\n",
    "feature_sels_vi = get_result_iv(all_feature_iv, low_th=0.01, high_th=0.5)\n",
    "sel_feature_ = list(feature_sels_vi.feature_name)  # 筛选后的特征列表：sel_feature_\n",
    "print('特征总个数:', all_feature_iv.shape[0])\n",
    "print('根据iv筛选后的剩余特征个数:',len(sel_feature_))\n",
    "feature_sels_vi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 根据相关性与iv筛选特征(连续性特征)\n",
    "# 注：相关性高的两个特征(阈值0.7)，可删除iv值较小的特征\n",
    "# 相关性分析：连续性特征(14个)\n",
    "sub_num_feature = list(df_s[sel_feature_])[3:]\n",
    "sub_char_feature = list(df_s[sel_feature_])[0:3]\n",
    "sn_df = df_s[sub_num_feature].corr()\n",
    "# 热力图\n",
    "plot_seaborn(sn_df)\n",
    "numf_vi = feature_sels_vi[3:].reset_index().drop('index', axis=1)\n",
    "\n",
    "# 可删除特征字段\n",
    "del_feature_subs = del_feature_sub(sn_df, numf_vi, th_c=0.7)\n",
    "print('删除特征字段：', len(del_feature_subs), '\\n', del_feature_subs)\n",
    "print('原特征字段：', len(sub_num_feature), '\\n', sub_num_feature)\n",
    "# 新的连续特征字段\n",
    "new_num_feature = [i for i in sub_num_feature if i not in del_feature_subs]\n",
    "print('新的特征字段：',len(new_num_feature), '\\n', new_num_feature)\n",
    "# 新的所有特征字段\n",
    "all_newFeature_sub = sub_char_feature + new_num_feature\n",
    "print('新的所有特征字段：',len(all_newFeature_sub), '\\n', all_newFeature_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 根据多重共线性筛选特征(连续型特征)\n",
    "# 判断：\n",
    "#    若VIF<3：说明基本不存在多重共线性的问题；\n",
    "#    若3<VIF<10：存在一定的多重共线性，实情考虑；\n",
    "#    若VIF>=10：说明问题比较严重，建议删除特征；\n",
    "vif_df = df_s[new_num_feature]\n",
    "print(vif_df.shape)\n",
    "numF_vif = pd.DataFrame()\n",
    "numF_vif['feature_name'] = vif_df.columns\n",
    "numF_vif['vif_v'] = [variance_inflation_factor(vif_df.values, i) for i in range(vif_df.shape[1])]\n",
    "print('最大VIF值：max(vif)=%s\\n' % max(numF_vif.vif_v))  # max(vif_v)<10，均无多重共线性，不操作\n",
    "numF_vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.模型建立与评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据准备_all_newFeature_sub\n",
    "df_model = df_s[all_newFeature_sub]\n",
    "df_model[sub_char_feature] = df_model[sub_char_feature].astype('str')\n",
    "print(df_model.shape)\n",
    "\n",
    "# 训练集和测试集划分：7：3\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_model, df_s['y'], test_size=0.3, random_state=10)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "def model_performance(y_train, pre_train, pro_train, y_test, pre_test, pro_test, plot=True):\n",
    "    # 训练集\n",
    "    print('Train:')\n",
    "    fpr0, tpr0, th0 = roc_curve(y_train, pro_train)\n",
    "    roc_auc0 = auc(fpr0, tpr0)\n",
    "    print('The model accuracy is {}'.format(accuracy_score(y_train, pre_train)))\n",
    "    print('The model f1 is {}'.format(f1_score(y_train, pre_train)))\n",
    "    print('The model p is {}'.format(precision_score(y_train, pre_train)))\n",
    "    print('The model recall is {}'.format(recall_score(y_train, pre_train)))\n",
    "    print('The confusion matrix is:\\n', confusion_matrix(y_train, pre_train))\n",
    "    if plot:\n",
    "        plot_roc_auc(fpr0, tpr0, roc_auc0)\n",
    "    \n",
    "    # 测试集\n",
    "    print('Test:')\n",
    "    fpr, tpr, th = roc_curve(y_test, pro_test)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print('The model accuracy is {}'.format(accuracy_score(y_test, pre_test)))\n",
    "    print('The model f1 is {}'.format(f1_score(y_test, pre_test)))\n",
    "    print('The model p is {}'.format(precision_score(y_test, pre_test)))\n",
    "    print('The model recall is {}'.format(recall_score(y_test, pre_test)))\n",
    "    print('The model KS is {}'.format(max(tpr - fpr)))\n",
    "    print('The confusion matrix is:\\n', confusion_matrix(y_test, pre_test))\n",
    "    if plot:\n",
    "        plot_roc_auc(fpr, tpr, roc_auc)\n",
    "    return fpr, tpr, roc_auc\n",
    "\n",
    "def plot_roc_auc(fpr, tpr, roc_auc):\n",
    "    plt.plot(fpr, tpr, label='AUC = {}'.format(roc_auc))\n",
    "    plt.title('ROC')\n",
    "    plt.xlabel('False positive rate')\n",
    "    plt.ylabel('True positive rate')\n",
    "    plt.legend()\n",
    "    plt.plot([0,1],[0,1], c='r')\n",
    "    plt.show()\n",
    "    \n",
    "def get_model_score(pro):\n",
    "    score = 520 - 48 * np.log(pro/(1-pro))\n",
    "    score = pd.Series(score).to_frame().rename(columns={0:'score'})\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 4.1 CatBoost模型 ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索策略--CatBoost\n",
    "def get_params_init():\n",
    "    params_init = {\n",
    "        'iterations':10,\n",
    "        'cat_features': [0,1,2],\n",
    "        'loss_function':'Logloss',\n",
    "        'depth':5,\n",
    "        'subsample':0.7,\n",
    "        'learning_rate':0.1,\n",
    "        'l2_leaf_reg':0.1,   \n",
    "    }\n",
    "    return params_init\n",
    "\n",
    "def get_tree_params():\n",
    "    params = {\n",
    "        'iterations':[10, 50, 100, 150, 200],\n",
    "        'depth':[5, 6, 7, 8],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_subsample_params():\n",
    "    params = {\n",
    "        'subsample':[0.5,0.6,0.7,0.8],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_learn_params():\n",
    "    params = {\n",
    "        'learning_rate':[0.01,0.05,0.1,0.15],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_l2_params():\n",
    "    params = {\n",
    "        'l2_leaf_reg':[0.1,0.5,1,2],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def grid_params_model(model, df, label):\n",
    "    # 参数组合\n",
    "    grid_params = [get_tree_params(), get_subsample_params(), get_learn_params(), get_l2_params()]\n",
    "    for _params_ in grid_params:\n",
    "        \n",
    "        gcv = GridSearchCV(estimator=model, param_grid=_params_, cv=5, iid=False)\n",
    "        gcv.fit(df, label)\n",
    "        print(gcv.scorer_, gcv.best_params_, gcv.best_score_)\n",
    "        # 参数更新\n",
    "        gcv_params =  model.get_params()\n",
    "        gcv_params.update(gcv.best_params_)\n",
    "        model.set_params(**gcv_params)\n",
    "        print('the other params!')\n",
    "    return model\n",
    "        \n",
    "def cat_model_run(df, label):\n",
    "    params_init = get_params_init()\n",
    "    # 初始模型\n",
    "    model_cb = cat.CatBoostClassifier(**params_init)\n",
    "    print(model_cb.get_params())\n",
    "    model_cb = grid_params_model(model_cb, df, label)\n",
    "    return model_cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练与结果\n",
    "model_cb = cat_model_run(x_train, y_train)\n",
    "model_cb.get_params()\n",
    "model_cb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "pre_train_cb = model_cb.predict(x_train)\n",
    "pro_train_cb = model_cb.predict_proba(x_train)[:,1]\n",
    "# 测试集\n",
    "pre_test_cb = model_cb.predict(x_test)\n",
    "pro_test_cb = model_cb.predict_proba(x_test)[:,1]\n",
    "\n",
    "fpr, tpr, _ = model_performance(y_train, pre_train_cb, pro_train_cb, y_test, pre_test_cb, pro_test_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型分数转换\n",
    "all_pro_cb = pd.concat([pd.Series(pro_train_cb), pd.Series(pro_test_cb)], axis=0)\n",
    "score_cat = get_model_score(all_pro_cb)\n",
    "print(score_cat.shape)\n",
    "# print('Max Score:%s' % max(score_cat.score))\n",
    "# print('Min Score:%s' % min(score_cat.score))\n",
    "# 分数整体分布图\n",
    "sn.distplot(score_cat['score'])\n",
    "score_cat['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性\n",
    "fimp_v = model_cb.get_feature_importance()\n",
    "fimp_n = model_cb.feature_names_\n",
    "fimp_vs = pd.Series(fimp_v).to_frame().rename(columns={0:'f_score'})\n",
    "fimp_ns = pd.Series(fimp_n).to_frame().rename(columns={0:'f_name'})\n",
    "fimp_result = pd.concat([fimp_ns, fimp_vs], axis=1)\n",
    "fimp_result = fimp_result.sort_values(by='f_score')\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.barh(range(len(fimp_result['f_score'])),fimp_result['f_score'])\n",
    "ax.set_yticks(range(len(fimp_result['f_name'])))\n",
    "ax.set_yticklabels(fimp_n)\n",
    "plt.title('CatBoost:Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 4.2 lightGBM模型 ======== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 编码方式可自由选择，也可以使用内置的categorical_feature\n",
    "# 训练集\n",
    "x_train_code = x_train.copy()\n",
    "for item in sub_char_feature:\n",
    "    x_train_code[item] = x_train_code[item].astype(\"category\").cat.codes +1\n",
    "# 测试集\n",
    "x_test_code = x_test.copy()\n",
    "for item in sub_char_feature:\n",
    "    x_test_code[item] = x_test_code[item].astype(\"category\").cat.codes +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?lgb.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索策略--lightGBM\n",
    "def get_params_init():\n",
    "    params_init = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate':0.01,\n",
    "        'max_depth':5,\n",
    "        'subsample':0.7,\n",
    "        'reg_alpha':0.0,\n",
    "        'reg_lambda':0.0, \n",
    "    }\n",
    "    return params_init\n",
    "\n",
    "def get_tree_params():\n",
    "    params = {\n",
    "        'n_estimators':[10, 50, 100, 150, 200],\n",
    "        'max_depth':[5, 6, 7, 8],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_subsample_params():\n",
    "    params = {\n",
    "        'subsample':[0.5,0.6,0.7,0.8],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_learn_params():\n",
    "    params = {\n",
    "        'learning_rate':[0.01,0.05,0.1,0.15],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def get_al_params():\n",
    "    params = {\n",
    "        'reg_alpha':[0.1,0.5,1,2],\n",
    "        'reg_lambda':[0.1,0.5,1,2],\n",
    "    }\n",
    "    return params\n",
    "\n",
    "def grid_params_model(model, df, label):\n",
    "    # 参数组合\n",
    "    grid_params = [get_tree_params(), get_subsample_params(), get_learn_params(), get_al_params()]\n",
    "    for _params_ in grid_params:\n",
    "        gcv = GridSearchCV(estimator=model, param_grid=_params_, cv=5, iid=False)\n",
    "        gcv.fit(df, label)\n",
    "        print(gcv.scorer_, gcv.best_params_, gcv.best_score_)\n",
    "        # 参数更新\n",
    "        gcv_params =  model.get_params()\n",
    "        gcv_params.update(gcv.best_params_)\n",
    "        model.set_params(**gcv_params)\n",
    "        print('the other params!')\n",
    "    return model\n",
    "        \n",
    "def lgb_model_run(df, label):\n",
    "    params_init = get_params_init()\n",
    "    # 初始模型\n",
    "    model_lgb = lgb.LGBMClassifier(**params_init)\n",
    "    print(model_lgb.get_params())\n",
    "    model_lgb = grid_params_model(model_lgb, df, label)\n",
    "    return model_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型训练与结果\n",
    "model_lgb = lgb_model_run(x_train_code, y_train)\n",
    "print(model_lgb.get_params())\n",
    "model_lgb.fit(x_train_code, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集\n",
    "pre_train_lgb = model_lgb.predict(x_train_code)\n",
    "pro_train_lgb = model_lgb.predict_proba(x_train_code)[:,1]\n",
    "# 测试集\n",
    "pre_test_lgb = model_lgb.predict(x_test_code)\n",
    "pro_test_lgb = model_lgb.predict_proba(x_test_code)[:,1]\n",
    "\n",
    "fpr, tpr, _ = model_performance(y_train, pre_train_lgb, pro_train_lgb, y_test, pre_test_lgb, pro_test_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型分数转换\n",
    "all_pro_lgb = pd.concat([pd.Series(pro_train_lgb), pd.Series(pro_test_lgb)], axis=0)\n",
    "score_lgb = get_model_score(all_pro_lgb)\n",
    "print(score_lgb.shape)\n",
    "# 分数整体分布图\n",
    "sn.distplot(score_lgb['score'])\n",
    "score_lgb['score'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征重要性\n",
    "fimp_v = model_lgb.booster_.feature_importance(importance_type='gain')\n",
    "fimp_n = model_lgb.booster_.feature_name()\n",
    "fimp_vs = pd.Series(fimp_v).to_frame().rename(columns={0:'f_score'})\n",
    "fimp_ns = pd.Series(fimp_n).to_frame().rename(columns={0:'f_name'})\n",
    "fimp_result = pd.concat([fimp_ns, fimp_vs], axis=1)\n",
    "fimp_result = fimp_result.sort_values(by='f_score')\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.barh(range(len(fimp_result['f_score'])),fimp_result['f_score'])\n",
    "ax.set_yticks(range(len(fimp_result['f_name'])))\n",
    "ax.set_yticklabels(fimp_n)\n",
    "plt.title('lightGBM:Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 4.3 XGBoost模型 ======== "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
